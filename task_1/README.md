# Task 1: Paper Reading: Attention is All You Need

Your task is to read and understand the seminal paper **[Attention is All You Need](https://arxiv.org/abs/1706.03762)** by Vaswani et al., which introduced the Transformer architecture that has revolutionized the field of natural language processing. Following it answer the questions provided in the `questionaire.md` file and write a brief summary of the paper.


This paper is foundational to understanding how modern large language models (LLMs) like GPT-3 and ChatGPT function.

## Instructions

1. **Read the Paper**: Start by thoroughly reading the paper. [Link to Paper](https://arxiv.org/abs/1706.03762)

A few additional resources to help you understand the paper better:
- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
- [3Blue1Brown: Neural Networks and Transformers (Playlist)](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [Attention? Attention!](https://www.youtube.com/watch?v=U0s0f995w14)


*Highly Recommendeded* to go through the above two resources for better understanding of the concepts.

2. **Summarize the Paper**: Write a summary of the paper in your own words. Just a jist, not more than 2 paragraphs (100 words).

Do this in the `summary.md` file.

3. **Complete the Questionnaire**:

In the same folder, you will find a file named `questionaire.md`. Please answer the questions provided in that file based on your understanding of the paper.